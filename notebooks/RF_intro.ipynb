{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from graphviz import Digraph\n",
    "\n",
    "from random import randrange, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    'font.size'           : 13,\n",
    "    'axes.titlesize'      : 'large'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Criteria\n",
    "\n",
    "#### Today I will be successful if I can...\n",
    "1. Explain bagging in one or two sentences\n",
    "1. Express why Random Forests work better than traditional Bagging\n",
    "1. Explain how increasing “n_estimators” will effect the random forest model’s accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine data\n",
    "wine_data = load_wine()\n",
    "\n",
    "#put dataset into data frame\n",
    "X = pd.DataFrame(wine_data['data'], columns=wine_data.feature_names)\n",
    "y = pd.Series(wine_data.target)\n",
    "X.rename({'od280/od315_of_diluted_wines':'protein_concentration'}, inplace = True, axis = 1)\n",
    "# X = X.iloc[:,3:]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at our classes\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split to enable model evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators will allow us to look at ensembling various numbers of trees\n",
    "n_estimators = np.arange(5, 51, 5)\n",
    "\n",
    "mean_train_accs = []\n",
    "mean_test_accs = []\n",
    "\n",
    "for n_trees in n_estimators:\n",
    "    #create n_trees number of trees ... stored in a list\n",
    "    trees = [DecisionTreeClassifier(max_depth = 2, random_state=42) for tree in range(n_trees)]\n",
    "    #fit each tree in list using training data\n",
    "    fits = [tree.fit(X_train, y_train) for tree in trees]\n",
    "    \n",
    "    #predict training and testing classes\n",
    "    y_hats_train  = [tree.predict(X_train) for tree in trees]\n",
    "    y_hats_test  = [tree.predict(X_test) for tree in trees]\n",
    "    \n",
    "    #chechout training and testing accuracy for each tree in list\n",
    "    test_accs = [accuracy_score(y_test, y_hat) for y_hat in y_hats_test]\n",
    "    train_accs = [accuracy_score(y_train, y_hat_train) for y_hat_train in y_hats_train]\n",
    "    #since we have 5, 10, 15... trees in list we can average \n",
    "    #their accuracies to see how increased tree number\n",
    "    #effects final score in model\n",
    "    mean_train_accs.append(np.mean(train_accs))\n",
    "    mean_test_accs.append(np.mean(test_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree for Classification Reminders\n",
    "    \n",
    "    \n",
    "    \n",
    "* Consider all binary splits based on a single feature:\n",
    "    * if the feature is categorical, split on value or not value.\n",
    "    * if the feature is numeric, split at a threshold: >threshold or <=threshold \n",
    "* Consider every possible split of every feature at every value\n",
    "* Pick the one split that provides the best information gain (entropy/gini impurity)\n",
    "* Use that split to create two new nodes and consider splitting them on every possible feature/value.\n",
    "* Stop when all nodes are pure or other stopping conditions like depth limit are met\n",
    "* Prune trees by merging nodes (ie., canceling a split)\n",
    "\n",
    "\n",
    "#### So what would two decision trees look like if they were trained on the same data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a nice visual of the decision trees\n",
    "def get_viz(tree, names = wine_data.target_names, feat_names = X.columns):\n",
    "    #use graphviz to create a decision tree viz\n",
    "    export_graphviz(tree, out_file='../images/tree.dot', feature_names = feat_names,\n",
    "                class_names = names,\n",
    "                rounded = True, proportion = False, precision = 2, filled = True)\n",
    "    #convert dot to png\n",
    "    !dot -Tpng ../images/tree.dot -o ../images/tree.png\n",
    "    return Image('../images/tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_viz(trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_viz(trees[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the exact same tree over and over... so we have an opportunity to get creative and get some variation with our trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracies accross varied num trees\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(list(n_estimators), mean_train_accs, label = 'Train', c='red', )\n",
    "plt.plot(list(n_estimators), mean_test_accs, label = 'Test', c = 'blue')\n",
    "plt.xlabel('Number of Estimators (Trees)')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Ensembled Decision Trees')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Try Bagging\n",
    "\n",
    "#### Bagging (Bootstrap + Aggregating)\n",
    "1. take bootstrapped samples of data (n_estimators determine how many samples to bootstrap)\n",
    "1. train chosen estimator/model continously from the bootstrapped datasets\n",
    "1. Average/Vote on all of the estimators to return a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn provides a bagging method\n",
    "n_estimators = np.arange(5, 201, 5)\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "basetree = DecisionTreeClassifier(max_depth = 2, random_state=123)\n",
    "\n",
    "for n_trees in n_estimators:\n",
    "    bag = BaggingClassifier(base_estimator=basetree, n_estimators=n_trees)\n",
    "    bag.fit(X_train, y_train)\n",
    "    y_hats_test =  bag.predict(X_test)\n",
    "    y_hats_train =  bag.predict(X_train)\n",
    "\n",
    "    train_accs.append(accuracy_score(y_hats_train, y_train)) \n",
    "    test_accs.append(accuracy_score(y_hats_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_viz(bag.estimators_[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_viz(bag.estimators_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracies accross different num trees\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(list(n_estimators), train_accs, label = 'Train', c='red')\n",
    "plt.plot(list(n_estimators), test_accs, label = 'Test', c = 'blue')\n",
    "plt.axhline(np.mean(mean_test_accs), ls = '--', label = 'Decision Tree Test Accuracy', c = 'k')\n",
    "plt.xlabel('Number of Estimators (Trees)')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Bagged Tree Scores')\n",
    "plt.ylim(0.8,1)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for a Random Forest\n",
    "\n",
    "In the above visuals, we see that there is still quite a bit of similarity between our bagged trees. This bit of randomness is helpful with our ensembling of decision trees but we still have some specific correlation. We can tell this because our accuracy is sitting tight between two thresholds. More bagged trees are no longer helping our ensemble. Highly independent trees are going to get us a more accurate ensemble method, this is where a second important \"randomness\" comes into play for Random Forest! \n",
    "\n",
    "To decorrelate the trees even more than bagging, we decide not to consider every feature for each split. The **features are randomly chosen at each split** in each tree. \n",
    "\n",
    "The *max_features* parameter helps change the number of considered features. In sklearn, max_features is set to 'auto' which is the square root of the number of features available in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators = np.arange(1,200, 5)\n",
    "train_accs_rf = []\n",
    "test_accs_rf = []\n",
    "for n_trees in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=n_trees, max_depth=2, random_state=12)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_hats_test =  rf.predict(X_test)\n",
    "    y_hats_train =  rf.predict(X_train)\n",
    "    train_accs_rf.append(accuracy_score(y_hats_train, y_train)) \n",
    "    test_accs_rf.append(accuracy_score(y_hats_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(list(n_estimators), train_accs_rf, label = 'Train', c='red', )\n",
    "plt.plot(list(n_estimators), test_accs_rf, label = 'Test', c = 'blue')\n",
    "plt.axhline(np.median(test_accs), ls = '--', c = 'k', label = 'Mean Bagging Accuracy')\n",
    "plt.xlabel('Number of Estimators (Trees)')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Random Forest Scores')\n",
    "# plt.ylim(0.4)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is typical that a Random Forest with more trees will return higher accuracy or R^2 but with diminishing returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_viz(rf.estimators_[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_viz(rf.estimators_[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1. What randomness can be refered to when discussing a Random Forest?\n",
    "1. When creating a Random Forest, how do you determine how many trees you should use?\n",
    "1. Would Random Forest work for regression as well as classification problems, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Strengths and Weaknesses\n",
    "\n",
    "Pros:\n",
    "1. One of most accurate learning algorithms available\n",
    "1. No need for feature scaling\n",
    "1. works for nonlinear relationships\n",
    "1. Maintains accuracy even when a large proportion of data is missing\n",
    "\n",
    "Cons:\n",
    "1. expensive to train (although it can be done in parallel) \n",
    "1. not as interpretable as other models we have discussed (lack of transparency in the process)\n",
    "\n",
    "### Parameters for Random Forest\n",
    "* n_estimators (number of trees)\n",
    "* max_features (number of features to consider at each split)\n",
    "* Any Decision tree Parameter\n",
    "* OOB_score (whether to use out of bag score to generalize accuracy/R^2)\n",
    "\n",
    "\n",
    "# Part 4 \n",
    "Reading/reviewing part 4 is designed to aid you regarding pair.md assignment\n",
    "\n",
    "\n",
    "##### OOB_score parameter explained\n",
    "* Each bootstrapped sample in the Random Forest classifier is trained on slightly different data and for each Decision Tree within the Random Forest, we have a holdout set called **\"out of bag sample\"**.\n",
    "\n",
    "* These samples will be predicted on for the other Decision Trees that did not contain the specific sample. \n",
    "* The final prediction of a row is determined by the \"majority vote\" or \"mean\" of all available DT predictions.\n",
    "* The OOB score is computed as the number of correctly predicted rows from the out of bag sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=2, n_estimators = 50, oob_score=True, random_state=12)\n",
    "rf.fit(X_train, y_train)\n",
    "y_hat = rf.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)\n",
    "#quick \"alternative\" for cross validation score\n",
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "For your paired assignment today, you are asked to create a confusion matrix of your results. Below we see a confusion matrix comprised from the wine data and the random forest classifier used in the above cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_hat)\n",
    "cm_df = pd.DataFrame(cm, index = [f'Wine_{i}' for i in rf.classes_], columns = [f'Wine_{i}' for i in rf.classes_])\n",
    "cm_df = cm_df/cm_df[cm_df.columns].sum()\n",
    "cm_df[cm_df == 0] = np.nan\n",
    "fig, ax = plt.subplots(1, figsize = (5,5))\n",
    "sns.heatmap(cm_df,annot=True, cmap='coolwarm', ax = ax, fmt='.2f', cbar=True, center = 0.02, \\\n",
    "            linewidths=1, linecolor='k')\n",
    "ax.set_title('RF Confusion Matrix', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a visual to show off a classification model's performance. Using the test data, we can see that there was 9%  of the actual wine_1 data which is predicted to be wine_0.\n",
    "\n",
    "**Queston**: What does the 1.00 in the center and the bottom right mean in a sentence?\n",
    "\n",
    "The deeper colors across the diagonal indicate a high accuracy model which is a sufficient model for balanced classes such as this wine dataset. It is not typical to get one's all the way accross the diagonal but we have an exceptionally small test set with a fairly clean data to begin with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next lecture will focus on finding possible ways to interpret our features through *Leave One Out Feature Importance* and *Partial Dependence plots*\n",
    "\n",
    "For now, take a look at the code below if you get far enough in the pair.md assignment to get an idea of how to visualize feature importance in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = np.argsort(rf.feature_importances_)\n",
    "print(\"top five:\", list(X.columns[feature_importances[-1:-6:-1]]))\n",
    "# these top five feature importances are hidden within Sklearn's methods that you can access.\n",
    "# This is a start but we can go deeper to see which features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a closer look at the individual trees in our forest to do a better job at understanding the features\n",
    "# finding the standard deviation can help us visualize the differences between each tree and it's view on the feature\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = list(X.columns[indices])\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(13), importances[indices], yerr=std[indices], align=\"center\")\n",
    "ax.set_xticks(range(13))\n",
    "ax.set_xticklabels(features, rotation = 90)\n",
    "ax.set_xlim([-1, 13])\n",
    "ax.set_xlabel(\"importance\")\n",
    "ax.set_title(\"Feature Importances\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
